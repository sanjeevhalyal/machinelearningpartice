{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a128d64c-bdee-45a6-ab73-d0ddb251882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "505e3978-1e48-4d93-b985-0e31b1b212c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-base (https://huggingface.co/t5-base)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bbf2d2486042e5bf90e2a7c9dbbe77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 20:04:20.249774: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-04-01 20:04:20.249908: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f137b7d4903246a38d2f03e6c0d6fe8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/850M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtranslation_en_to_de\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/MachineLearning-3.8/lib/python3.8/site-packages/transformers/pipelines/__init__.py:567\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;66;03m# Infer the framework from the model\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# Forced if framework already defined, inferred if it's None\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;66;03m# Will load the correct model if possible\u001b[39;00m\n\u001b[1;32m    566\u001b[0m model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 567\u001b[0m framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    579\u001b[0m load_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(model_config) \u001b[38;5;129;01min\u001b[39;00m TOKENIZER_MAPPING \u001b[38;5;129;01mor\u001b[39;00m model_config\u001b[38;5;241m.\u001b[39mtokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/MachineLearning-3.8/lib/python3.8/site-packages/transformers/pipelines/base.py:256\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to load the model with Tensorflow.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m     )\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    258\u001b[0m         model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/.conda/envs/MachineLearning-3.8/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py:446\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    445\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/MachineLearning-3.8/lib/python3.8/site-packages/transformers/modeling_utils.py:2007\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2001\u001b[0m     archive_file \u001b[38;5;241m=\u001b[39m hf_bucket_url(\n\u001b[1;32m   2002\u001b[0m         pretrained_model_name_or_path, filename\u001b[38;5;241m=\u001b[39mfilename, revision\u001b[38;5;241m=\u001b[39mrevision, mirror\u001b[38;5;241m=\u001b[39mmirror\n\u001b[1;32m   2003\u001b[0m     )\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2006\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m-> 2007\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2008\u001b[0m \u001b[43m        \u001b[49m\u001b[43marchive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2014\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2015\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2016\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2018\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m   2019\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2021\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2022\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken having permission to this repo with `use_auth_token` or log in with `huggingface-cli \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogin` and pass `use_auth_token=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2024\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/MachineLearning-3.8/lib/python3.8/site-packages/transformers/utils/hub.py:284\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    280\u001b[0m     local_files_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m url_or_filename\n",
      "File \u001b[0;32m~/.conda/envs/MachineLearning-3.8/lib/python3.8/site-packages/transformers/utils/hub.py:594\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m temp_file_manager() \u001b[38;5;28;01mas\u001b[39;00m temp_file:\n\u001b[1;32m    592\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in cache or force_download set to True, downloading to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemp_file\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 594\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    596\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstoring \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    597\u001b[0m os\u001b[38;5;241m.\u001b[39mreplace(temp_file\u001b[38;5;241m.\u001b[39mname, cache_path)\n",
      "File \u001b[0;32m~/.conda/envs/MachineLearning-3.8/lib/python3.8/site-packages/transformers/utils/hub.py:446\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# `tqdm` behavior is determined by `utils.logging.is_progress_bar_enabled()`\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;66;03m# and can be set using `utils.logging.enable/disable_progress_bar()`\u001b[39;00m\n\u001b[1;32m    438\u001b[0m progress \u001b[38;5;241m=\u001b[39m tqdm(\n\u001b[1;32m    439\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    440\u001b[0m     unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    445\u001b[0m )\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m):\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m~/.conda/envs/MachineLearning-3.8/lib/python3.8/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/.conda/envs/MachineLearning-3.8/lib/python3.8/site-packages/urllib3/response.py:627\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp):\n\u001b[0;32m--> 627\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    630\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/MachineLearning-3.8/lib/python3.8/site-packages/urllib3/response.py:566\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    563\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 566\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m         flush_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/MachineLearning-3.8/lib/python3.8/site-packages/urllib3/response.py:532\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buffer\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/.conda/envs/MachineLearning-3.8/lib/python3.8/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 459\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/MachineLearning-3.8/lib/python3.8/http/client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    498\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/.conda/envs/MachineLearning-3.8/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/MachineLearning-3.8/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.conda/envs/MachineLearning-3.8/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline(\"translation_en_to_de\", model=\"<---?>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55ef087-6f2b-410e-b1f4-8c0e03eabf3d",
   "metadata": {},
   "source": [
    "## Machine translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2514213c-0278-444d-a420-1cec833366d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06a18e7f-3d1f-4208-ae39-a10e652f2885",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset kde4 (/Users/sanjeevhalyal/.cache/huggingface/datasets/kde4/en-fr-lang1=en,lang2=fr/0.0.0/243129fb2398d5b0b4f7f6831ab27ad84774b7ce374cf10f60f6e1ff331648ac)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007544755935668945,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a2f4cb8e454db39b964f8df6af5a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data =  load_dataset(\"kde4\", lang1=\"en\", lang2=\"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc658134-35c1-4544-9509-65950f9021a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 210173\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "012868ce-9dbd-42ea-af08-68f9fcb031fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/sanjeevhalyal/.cache/huggingface/datasets/kde4/en-fr-lang1=en,lang2=fr/0.0.0/243129fb2398d5b0b4f7f6831ab27ad84774b7ce374cf10f60f6e1ff331648ac/cache-71dca23ed0a2dee3.arrow\n"
     ]
    }
   ],
   "source": [
    "small = raw_data[\"train\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fad353e5-0e40-4ff5-a043-f17b2eec1f79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /Users/sanjeevhalyal/.cache/huggingface/datasets/kde4/en-fr-lang1=en,lang2=fr/0.0.0/243129fb2398d5b0b4f7f6831ab27ad84774b7ce374cf10f60f6e1ff331648ac/cache-7bcb4e78b95a31f5.arrow and /Users/sanjeevhalyal/.cache/huggingface/datasets/kde4/en-fr-lang1=en,lang2=fr/0.0.0/243129fb2398d5b0b4f7f6831ab27ad84774b7ce374cf10f60f6e1ff331648ac/cache-a365e05d934a9e32.arrow\n"
     ]
    }
   ],
   "source": [
    "split = small.train_test_split(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a85c394-2abd-4184-a5e1-252446c2a7ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'translation'],\n",
       "         num_rows: 750\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'translation'],\n",
       "         num_rows: 250\n",
       "     })\n",
       " }),\n",
       " {'id': '169005',\n",
       "  'translation': {'en': '& Reduce Tree', 'fr': \"& Refermer l' arborescence\"}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split, split[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c847242a-b5ff-4f11-ad2a-2b2641b8ba45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install sentencepiece\n",
    "# !pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72ada11c-88ee-4d45-89ca-d1701f786da0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d0f1751-dd2d-421c-8d28-62ec08d62900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_sample = split[\"train\"][5][\"translation\"][\"en\"]\n",
    "fr_sample = split[\"train\"][5][\"translation\"][\"fr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "005ae2a3-efca-4fbb-a6de-518d9bf754a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('You can either pick a file or enter its name in the Location: box.',\n",
       " ['▁You',\n",
       "  '▁can',\n",
       "  '▁either',\n",
       "  '▁pick',\n",
       "  '▁a',\n",
       "  '▁file',\n",
       "  '▁or',\n",
       "  '▁enter',\n",
       "  '▁its',\n",
       "  '▁name',\n",
       "  '▁in',\n",
       "  '▁the',\n",
       "  '▁Location',\n",
       "  ':',\n",
       "  '▁box',\n",
       "  '.',\n",
       "  '</s>'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_ids = tokenizer(en_sample)\n",
    "\n",
    "en_sample, tokenizer.convert_ids_to_tokens(en_ids[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "284f2130-a35b-473f-be97-15123996a6ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([469., 131.,  40.,  28.,  10.,  15.,  15.,   5.,   5.,   4.,   0.,\n",
       "          6.,   4.,   3.,   2.,   1.,   2.,   1.,   1.,   1.,   1.,   2.,\n",
       "          0.,   2.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   1.]),\n",
       " array([1.00000e+00, 2.67200e+01, 5.24400e+01, 7.81600e+01, 1.03880e+02,\n",
       "        1.29600e+02, 1.55320e+02, 1.81040e+02, 2.06760e+02, 2.32480e+02,\n",
       "        2.58200e+02, 2.83920e+02, 3.09640e+02, 3.35360e+02, 3.61080e+02,\n",
       "        3.86800e+02, 4.12520e+02, 4.38240e+02, 4.63960e+02, 4.89680e+02,\n",
       "        5.15400e+02, 5.41120e+02, 5.66840e+02, 5.92560e+02, 6.18280e+02,\n",
       "        6.44000e+02, 6.69720e+02, 6.95440e+02, 7.21160e+02, 7.46880e+02,\n",
       "        7.72600e+02, 7.98320e+02, 8.24040e+02, 8.49760e+02, 8.75480e+02,\n",
       "        9.01200e+02, 9.26920e+02, 9.52640e+02, 9.78360e+02, 1.00408e+03,\n",
       "        1.02980e+03, 1.05552e+03, 1.08124e+03, 1.10696e+03, 1.13268e+03,\n",
       "        1.15840e+03, 1.18412e+03, 1.20984e+03, 1.23556e+03, 1.26128e+03,\n",
       "        1.28700e+03]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = split[\"train\"][\"translation\"]\n",
    "input_len = [len(tr[\"en\"]) for tr in train]\n",
    "\n",
    "\n",
    "plt.hist(input_len, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "db79b700-1254-41b0-8185-cf8ad1cdf74b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [461, 2130, 5909, 6020, 590, 239, 567, 9071, 900, 1248, 34, 5094, 3534, 108, 239, 567, 62, 1794, 1248, 113, 170, 122, 31, 8, 1283, 5, 1863, 51, 9831, 35646, 3, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'input_ids': [344, 1069, 345, 4094, 34, 2428, 345, 9315, 113, 689, 31, 8, 1283, 5, 1470, 21708, 3, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Vous pouvez soit choisir un fichier soit saisir son nom dans la zone de texte Emplacement.\n",
      "['▁Vous', '▁pouvez', '▁soit', '▁choisir', '▁un', '▁fichier', '▁soit', '▁saisir', '▁son', '▁nom', '▁dans', '▁la', '▁zone', '▁de', '▁texte', '▁Emplacement', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(fr_sample))\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    fr_ids = tokenizer(fr_sample)\n",
    "    print(fr_ids)\n",
    "    print(fr_sample)\n",
    "    print(tokenizer.convert_ids_to_tokens(fr_ids[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ddd37695-df63-4428-9469-547571a88120",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [461, 2130, 5909, 6020, 590, 239, 567, 9071, 900, 1248, 34, 5094, 3534, 108, 239, 567, 62, 1794, 1248, 113, 170, 122, 31, 8, 1283, 5, 1863, 51, 9831, 35646, 3, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Vous pouvez soit choisir un fichier soit saisir son nom dans la zone de texte Emplacement.\n",
      "['▁V', 'ous', '▁po', 'uv', 'ez', '▁so', 'it', '▁cho', 'is', 'ir', '▁un', '▁fi', 'chi', 'er', '▁so', 'it', '▁s', 'ais', 'ir', '▁son', '▁no', 'm', '▁dans', '▁la', '▁zone', '▁de', '▁text', 'e', '▁Em', 'placement', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# Bad example \n",
    "_fr_ids = tokenizer(fr_sample)\n",
    "print(_fr_ids)\n",
    "print(fr_sample)\n",
    "print(tokenizer.convert_ids_to_tokens(_fr_ids[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d940effe-91ef-4adf-8ddd-765273fe1c27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_input_len = 128\n",
    "max_target_len = 128\n",
    "\n",
    "def tokenizer_fn(batch):\n",
    "    inputs = [x['en'] for x in batch['translation']]\n",
    "    targets = [x['fr'] for x in batch['translation']]\n",
    "\n",
    "    tokenized_inputs = tokenizer(\n",
    "        inputs, max_length=max_input_len, truncation=True)\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        tokenized_targets = tokenizer(\n",
    "            targets, max_length=max_target_len, truncation=True)\n",
    "  \n",
    "    tokenized_inputs['labels'] = tokenized_targets['input_ids']\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "304f99ce-8f3f-4f35-b3e7-bfd341e58306",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/sanjeevhalyal/.cache/huggingface/datasets/kde4/en-fr-lang1=en,lang2=fr/0.0.0/243129fb2398d5b0b4f7f6831ab27ad84774b7ce374cf10f60f6e1ff331648ac/cache-a405013393c7ab70.arrow\n",
      "Loading cached processed dataset at /Users/sanjeevhalyal/.cache/huggingface/datasets/kde4/en-fr-lang1=en,lang2=fr/0.0.0/243129fb2398d5b0b4f7f6831ab27ad84774b7ce374cf10f60f6e1ff331648ac/cache-c4f2d80499f18947.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = split.map(\n",
    "    tokenizer_fn,\n",
    "    batched=True,\n",
    "    remove_columns=split['train'].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "91c4f09d-4238-48dd-9e0a-882e81b9fb6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[402, 34933, 29244, 0],\n",
       "  [526, 3261, 0],\n",
       "  [3492,\n",
       "   3070,\n",
       "   6443,\n",
       "   37,\n",
       "   443,\n",
       "   61,\n",
       "   32,\n",
       "   317,\n",
       "   2203,\n",
       "   4824,\n",
       "   514,\n",
       "   1807,\n",
       "   971,\n",
       "   4,\n",
       "   4124,\n",
       "   3,\n",
       "   0]],\n",
       " 'attention_mask': [[1, 1, 1, 1],\n",
       "  [1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " 'labels': [[402, 9950, 108, 2240, 14, 6, 38367, 13218, 0],\n",
       "  [526, 3261, 0],\n",
       "  [34023,\n",
       "   5,\n",
       "   3948,\n",
       "   5,\n",
       "   372,\n",
       "   402,\n",
       "   38492,\n",
       "   350,\n",
       "   823,\n",
       "   95,\n",
       "   13439,\n",
       "   2,\n",
       "   25985,\n",
       "   14,\n",
       "   6,\n",
       "   3996,\n",
       "   3,\n",
       "   0]]}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_dataset[\"train\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "43de579a-ba63-4fa8-8024-705f63d6dc9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-en-fr/resolve/main/config.json from cache at /Users/sanjeevhalyal/.cache/huggingface/transformers/5ad88432037ab18b1eb95761258d2b1b3a32e1e401d5f610f86eb3f479e59e8c.c4ed4c40cbcad4e407fe9d49751d86cfbd347e4cb4edd0cdd23f501d9c3d088c\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-en-fr\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59513\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 59513,\n",
      "  \"decoder_vocab_size\": 59514,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 59513,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.20.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 59514\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/Helsinki-NLP/opus-mt-en-fr/resolve/main/pytorch_model.bin from cache at /Users/sanjeevhalyal/.cache/huggingface/transformers/df7925366c58e84bcbddeab1100929d66148fffbba2fdacddfa3bc9b396c5dc8.6e73740b296c2a7675d00232d5974e8056cf443063edf436f82939e35e9eef29\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-fr.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dadeed90-75af-4123-a8fe-7f7057edd0e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "993b9285-f77f-43b6-bf44-334d1d7d9104",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '46472',\n",
       " 'translation': {'en': 'You can either pick a file or enter its name in the Location: box.',\n",
       "  'fr': 'Vous pouvez soit choisir un fichier soit saisir son nom dans la zone de texte Emplacement.'}}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split[\"train\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9aaf234c-7663-4ca7-8fee-ffe859d69c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[402, 34933, 29244, 0],\n",
       "  [526, 3261, 0],\n",
       "  [3492,\n",
       "   3070,\n",
       "   6443,\n",
       "   37,\n",
       "   443,\n",
       "   61,\n",
       "   32,\n",
       "   317,\n",
       "   2203,\n",
       "   4824,\n",
       "   514,\n",
       "   1807,\n",
       "   971,\n",
       "   4,\n",
       "   4124,\n",
       "   3,\n",
       "   0]],\n",
       " 'attention_mask': [[1, 1, 1, 1],\n",
       "  [1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " 'labels': [[402, 9950, 108, 2240, 14, 6, 38367, 13218, 0],\n",
       "  [526, 3261, 0],\n",
       "  [34023,\n",
       "   5,\n",
       "   3948,\n",
       "   5,\n",
       "   372,\n",
       "   402,\n",
       "   38492,\n",
       "   350,\n",
       "   823,\n",
       "   95,\n",
       "   13439,\n",
       "   2,\n",
       "   25985,\n",
       "   14,\n",
       "   6,\n",
       "   3996,\n",
       "   3,\n",
       "   0]]}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_dataset[\"train\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3b297819-1d77-46ab-9d0f-56b48792a5da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(1, 3)])\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d6850cd0-a008-41af-a23c-8f62683e95b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  526,  3261,     0, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
       "         59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
       "         59513, 59513, 59513, 59513],\n",
       "        [ 3492,    14,  1360,     9, 21303,   259,    37,    47,   483,    61,\n",
       "            32,   317,  2203,  4824,   514,   357,   352,  5482,   971,     4,\n",
       "            39, 29830,     3,     0]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bd401251-ef87-4bcd-972c-3dd414fafdc0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁K',\n",
       " 'DE',\n",
       " '</s>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first token is a pad!\n",
    "tokenizer.convert_ids_to_tokens(batch[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "688c75d7-1510-431d-9993-518781e14862",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " '▁K',\n",
       " 'DE',\n",
       " '</s>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first token is a pad!\n",
    "tokenizer.convert_ids_to_tokens(batch[\"decoder_input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22629309-48fb-4a0f-93fb-041901d4a8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
